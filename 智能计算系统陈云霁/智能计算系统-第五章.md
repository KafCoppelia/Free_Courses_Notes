# Chapter 5 编程框架机理
## 5.1 TF设计原则
1. 高性能
	- TF算子，设计过程中已针对底层硬件架构进行了充分优化；
	- 针对生成的计算图，TF又提供了一系列优化操作，以提升计算图的运行效率；
	- TF调度器可以根据网络结构特点，并发运行没有数据依赖的节点，例如：
```python
import tensorflow as tf
a = tf.constant(1.0)
b = tf.constant(2.0)
c = tf.sin(a)
d = tf.cos(b)
e = tf.add(c, d) # 张量c, d可以并发执行

with tf.Session() as sess:
	sess.run(e)
```
2. 易开发
	- TF针对现有多种深度学习算法，提取大量的共性运算，并封装成算子；
	- 用户使用TF进行算法开发时，能直接调用这些算子，很方便地实现算法；
3. 可移植
	- TF可工作于各种类型的异构系统；
	- 对每个算子（例如矩阵乘法）需提供在不同设备上的不同底层实现；
	- 通过上述机制，使得统一的用户程序可以在不同硬件平台上执行；

## 5.2 TF计算图机制
### 计算图的自动求导
- 深度学习中采用**梯度下降法**更新模型参数；
- 梯度计算比较直观，但对于复杂模型，手动计算梯度非常困难；
- 目前大部分深度学习框架均提供自动梯度计算功能；
- 用户只需描述**前向计算的过程**，由变成框架自动推导反向计算图，完成导数计算；

常用求导方法：
- 手动求解
	- 即传统的反向传播法：手动用链式法则求解出梯度公式，代入数值，得到最终梯度值；
	- 缺点：
		  1. 对于大规模的深度学习计算，手动用链式法则进行梯度计算并转换成计算机程序困难；
		  2. 需要手动编写梯度求解代码；
		  3. 每次修改算法模型，都要修改对应的梯度求解算法；
```mermaid
flowchart LR
	w --> matmul --y1--> add --> y3
	x --> matmul
	b --y2--> add
```
```mermaid
flowchart RL
	y3 --> add --y2--> b
	add --y1--> matmul --> w
	matmul --> x
```
- 数值求导：一开始直接代入数值近似求解
	- 利用导数的原始定义求解：$f'(x)=\displaystyle\lim_{h\rightarrow 0}\dfrac{f(x+h)-f(x)}{h}$
	- 优点：
		  1. 易操作；
		  2. 可对用户隐藏求解过程；
	- 缺点：
		1. 计算量大，求解速度慢；
		2. 可能引入舍入误差和截断误差；
- 符号求导法：直接对代数表达式求解，最后才代入数字
	- 利用求导规则来对表达式进行自动操作，从而获得导数；
	- 常见求导规则：
	$\dfrac{d}{dx}\left(f(x)+g(x)\right)=\dfrac{d}{dx}f(x)+\dfrac{d}{dx}g(x)$
	$\dfrac{d}{dx}f(x)g(x)=\left(\dfrac{d}{dx}f(x)\right)g(x)+f(x)\left(\dfrac{d}{dx}g(x)\right)$
	$\dfrac{d}{dx}\dfrac{f(x)}{g(x)}=\dfrac{f'(x)g(x)-f(x)g'(x)}{g(x)^2}$
	- 缺点：表达式膨胀问题；
- 自动求导法：介于数值求导和符号求导的方法；
	- 计算图结构天然适用于自动求导：计算图将多输入的复杂计算表达成了由多个基本二元计算组成的**有向图**，并保留了所有中间变量，有助于程序自动利用链式法则进行求导；
	- 优点
		1. 灵活，可以完全向用户隐藏求导过程；
		2. 只对基本函数运用符号求导法，因此可以灵活结合变成语言的循环结构、条件结构等；
```mermaid
graph LR
A[对基本算子应用符号求导法] --> B[代入数值 保留中间结果] --> C[应用于整个函数]
```
- 对比：

  |   方法   | 对图的遍历次数 | 精度 |             备注             |
  | :------: | :------------: | :--: | :--------------------------: |
  | 手动求解 |       NA       |  高  |             复杂             |
  | 数值求导 |    $n_I+1$     |  低  |         计算量大，慢         |
  | 符号求导 |       NA       |  高  |          表达式膨胀          |
  | 自动求导 |    $n_O+1$     |  高  | 对输入维度较大的情况优势明显 |

### 检查点机制

在模型训练过程中，可以保存模型中的所有变量；

### TF中的控制流

- TF中使用控制流算子来实现不同复杂控制流场景；

- 通过引入少量简单基础操作，为多样的TF应用提供丰富控制流表达；
- 每一个操作都会在一个**执行帧**中被执行，控制流操作负责创建和管理这些执行帧；

### 计算图的执行模式

- client：tongguo session接口与master和worker接口通信，worker可以是一个或多个；
- master：控制所有worker按照计算图执行；
- worker：每一个worker负责一个或多个计算设备的仲裁访问，并根据master指令，执行计算图节点；
- 设备：CPU或GPU；

### 分布式执行

client、master、worker工作与不同机器上的不同进程中；

### 计算图本地执行

1. 计算图剪枝：得到本地运行的最小子图；
2. 计算图分配：多设备，保证计算快速执行；
3. 计算图优化；
   1. 常量折叠；
   2. 算数优化；
   3. 布局优化；
   4. 重映射：算子融合，将出现频率较高的子图用一单独算子代替；
4. 计算图切分；

### 计算图分布式执行

- 神经网络规模和数据规模指数级增加；
- 提高训练效率，采用分布式技术：将大CNN拆分成许多小的部分，同时分配在多个节点上进行计算；

### 分布式通信

- 点到点通信；
- 集合通信；

### 容错机制

确保分布式系统的稳定；

- 检查Send和Recv节点传输的正确性；
- 定期检查每个工作机的状态；
- 检查到错误时，计算图执行过程停止并重启；
- 训练过程中会保存中间状态，用于恢复；

## 5.3 TF系统实现

### 整体架构

### 计算图执行模块

### 执行器逻辑

执行流：一个能存储计算任务的队列；流间任务可以并行执行，流内任务串行执行；

### 设备抽象和管理

- TF将设备分为本地设备、远程设备；

- TF使用注册机制管理设备。每个设备负责一个子图运算，通过注册接口支持自定义设备；

### 算子实现

略